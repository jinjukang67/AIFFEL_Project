{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acce90ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "956936cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data/scissor\n",
      "1300  images to be resized.\n",
      "1300  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "1300  images to be resized.\n",
      "1300  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "1300  images to be resized.\n",
      "1300  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지 불러와서 28X28 사이즈 변경\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "#image_dir_path = os.getenv(\"HOME\") + \"/Documents/아이펠/[EX_01]/train_data/scissor\"\n",
    "image_dir_path = \"train_data/scissor\"\n",
    "print(image_dir_path)\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path1 = \"train_data/rock\"\n",
    "resize_images(image_dir_path1)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "#image_dir_path2 = os.getenv(\"HOME\") + \"~/train_data/paper\"\n",
    "image_dir_path2 = 'train_data/paper'\n",
    "resize_images(image_dir_path2)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb9742",
   "metadata": {},
   "source": [
    "# 데이터 가져오는 load_data() 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16ea4ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 3900 입니다.\n",
      "x_train shape: (3900, 28, 28, 3)\n",
      "y_train shape: (3900,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path, number_of_data=3900):\n",
    "    img_size=28\n",
    "    color=3\n",
    "    # 이미지 데이터와 라벨 데이터 담을 행렬 생성\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "    idx=0\n",
    "    \n",
    "    # glob() 함수는 인자로 받은 패턴과 이름 일치하는 모든 파일과 디렉터리의 리스트 반환\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32) # 예를 들어 0.jpg을 가지고 온다면\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        # imgs[0,28(img_size_w),28(img_size_h),color]=img \n",
    "        \n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "#image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "image_dir_path = \"train_data/\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "478429d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(x_train[300])\n",
    "print('라벨: ', y_train[300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a15df1b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3900\n",
      "3900\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e657a71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 800)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                25632     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "122/122 [==============================] - 2s 9ms/step - loss: 1.0260 - accuracy: 0.4951\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.6079 - accuracy: 0.7808\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.3330 - accuracy: 0.8862\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.2197 - accuracy: 0.9259\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.1530 - accuracy: 0.9546\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.1127 - accuracy: 0.9664\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0669 - accuracy: 0.9856\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.0523 - accuracy: 0.9903\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.0367 - accuracy: 0.9923\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.0282 - accuracy: 0.9956\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 800)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                25632     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 바꿔 볼 수 있는 하이퍼파라미터들\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=10\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8204993d",
   "metadata": {},
   "source": [
    "# 테스트셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc8f56b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300  images to be resized.\n",
      "300  images resized.\n",
      "300  images to be resized.\n",
      "300  images resized.\n",
      "300  images to be resized.\n",
      "300  images resized.\n",
      "모든 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 이미지 사이즈 28x28로 변경\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "#image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "image_dir_path = \"test_data/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "#image_dir_path1 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "image_dir_path1 = \"test_data/rock\"\n",
    "resize_images(image_dir_path1)\n",
    "#image_dir_path2 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "image_dir_path2 = \"test_data/paper\"\n",
    "resize_images(image_dir_path2)\n",
    "\n",
    "print(\"모든 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cad6b53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_test)의 이미지 개수는 900 입니다.\n",
      "x_test shape: (900, 28, 28, 3)\n",
      "y_test shape: (900,)\n"
     ]
    }
   ],
   "source": [
    "def load_test(img_path, number_of_data=900):\n",
    "    img_size=28\n",
    "    color=3\n",
    "    # 이미지 데이터와 라벨 데이터 담을 행렬 생성\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = \"test_data\"\n",
    "(x_test, y_test)=load_test(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564995f2",
   "metadata": {},
   "source": [
    "# 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91162b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 0s - loss: 1.8284 - accuracy: 0.6433 - 258ms/epoch - 9ms/step\n",
      "test_loss: 1.8283898830413818 \n",
      "test_accuracy: 0.6433333158493042\n"
     ]
    }
   ],
   "source": [
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa159d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
